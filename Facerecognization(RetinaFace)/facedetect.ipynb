{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2262a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install retina-face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eac6dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import transform as trans\n",
    "import onnxruntime as rt\n",
    "from retinaface import RetinaFace\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3d70775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face Detection(使用 Python API MTCNN、RetinaFace)-本次實作使用RetinaFace\n",
    "# 偵測人臉~輸出會有預測框左上角跟右下角、兩個眼睛、鼻子、嘴巴兩邊的座標值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd6814b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#臉部偵測function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc14e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detect(img_path):\n",
    "    img_bgr = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    detections = detector.predict(img_rgb)\n",
    "    return img_rgb, detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a517de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detector = RetinaFace(quality=\"normal\")\n",
    "# img_path='Suzy.jpg'\n",
    "# img_rgb, detections = face_detect(img_path)\n",
    "# print(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a480865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_result = detector.draw(img_rgb, detections)\n",
    "# img = cv2.cvtColor(img_result, cv2.COLOR_RGB2BGR)\n",
    "# cv2.imshow(\"windows\", img)\n",
    "# key = cv2.waitKey()\n",
    "# if key == ord(\"q\"):\n",
    "#    print(\"exit\")\n",
    "\n",
    "# cv2.destroyWindow(\"windows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd2402b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#臉部對齊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1114fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_align(img_rgb, landmarks):\n",
    "    src = np.array([\n",
    "        [30.2946, 51.6963],\n",
    "        [65.5318, 51.5014],\n",
    "        [48.0252, 71.7366],\n",
    "        [33.5493, 92.3655],\n",
    "        [62.7299, 92.2041] ], dtype=np.float32)\n",
    "    dst = np.array(landmarks, dtype=np.float32).reshape(5, 2)\n",
    "    tform = trans.SimilarityTransform()\n",
    "    tform.estimate(dst, src)\n",
    "    M = tform.params[0:2,:]\n",
    "    aligned = cv2.warpAffine(img_rgb, M, (112, 112), borderValue = 0)\n",
    "\n",
    "    return aligned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f17aba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#臉部提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "439b8ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(img_rgb, detections):\n",
    "    position = []\n",
    "    landmarks = []\n",
    "    embeddings = np.zeros((len(detections), 512))\n",
    "    for i, face_info in enumerate(detections):\n",
    "        face_position = [face_info['x1'], face_info['y1'], face_info['x2'], face_info['y2']]\n",
    "        face_landmarks = [face_info['left_eye'], face_info['right_eye'], face_info['nose'], face_info['left_lip'],\n",
    "                     face_info['right_lip']]\n",
    "\n",
    "        position.append(face_position)\n",
    "        landmarks.append(face_landmarks)\n",
    "\n",
    "        aligned = face_align(img_rgb, face_landmarks)\n",
    "        t_aligned = np.transpose(aligned, (2, 0, 1))\n",
    "\n",
    "        inputs = t_aligned.astype(np.float32)\n",
    "        input_blob = np.expand_dims(inputs, axis=0)\n",
    "\n",
    "        first_input_name = extractor.get_inputs()[0].name\n",
    "        first_output_name = extractor.get_outputs()[0].name\n",
    "\n",
    "        predict = extractor.run([first_output_name], {first_input_name: input_blob})[0]\n",
    "        final_embedding = normalize(predict).flatten()\n",
    "\n",
    "        embeddings[i] = final_embedding\n",
    "\n",
    "    return position, landmarks, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a62f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_array(arr):\n",
    "   out = io.BytesIO()\n",
    "   np.save(out, arr)\n",
    "   out.seek(0)\n",
    "   return sqlite3.Binary(out.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2f04d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_array(text):\n",
    "   out = io.BytesIO(text)\n",
    "   out.seek(0)\n",
    "   return np.load(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ef1fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file_path):\n",
    "    file_data = {}\n",
    "    for person_name in os.listdir(file_path):\n",
    "        person_file = os.path.join(file_path, person_name)\n",
    "\n",
    "        total_pictures = []\n",
    "        for picture in os.listdir(person_file):\n",
    "            picture_path = os.path.join(person_file, picture)\n",
    "            total_pictures.append(picture_path)\n",
    "\n",
    "        file_data[person_name] = total_pictures\n",
    "\n",
    "    return file_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98bda6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db(db_path, file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        conn_db = sqlite3.connect(db_path)\n",
    "        conn_db.execute(\"CREATE TABLE face_info \\\n",
    "                         (id INT PRIMARY KEY NOT NULL, \\\n",
    "                         name TEXT NOT NULL, \\\n",
    "                         embedding ARRAY NOT NULL)\")\n",
    "\n",
    "        file_data = load_file(file_path)\n",
    "        for i, person_name in enumerate(file_data.keys()):\n",
    "            picture_path = file_data[person_name]\n",
    "            sum_embeddings = np.zeros([1, 512])\n",
    "            for j, picture in enumerate(picture_path):\n",
    "                img_rgb, detections = face_detect(picture)\n",
    "                position, landmarks, embeddings = get_embeddings(img_rgb, detections)\n",
    "                sum_embeddings += embeddings\n",
    "\n",
    "            final_embedding = sum_embeddings / len(picture_path)\n",
    "            adapt_embedding = adapt_array(final_embedding)\n",
    "\n",
    "            conn_db.execute(\"INSERT INTO face_info (id, name, embedding) VALUES (?, ?, ?)\",(i, person_name, adapt_embedding))\n",
    "        conn_db.commit()\n",
    "        conn_db.close()\n",
    "\n",
    "    else:\n",
    "        print(\"database file does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f75384a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_face(embeddings, threshold):\n",
    "    conn_db = sqlite3.connect(db_path)\n",
    "    cursor = conn_db.execute(\"SELECT * FROM face_info\")\n",
    "    db_data = cursor.fetchall()\n",
    "\n",
    "    total_distances = []\n",
    "    total_names = []\n",
    "    for data in db_data:\n",
    "        total_names.append(data[1])\n",
    "        db_embeddings = convert_array(data[2])\n",
    "        distance = round(np.linalg.norm(db_embeddings - embeddings), 2)\n",
    "        total_distances.append(distance)\n",
    "    total_result = dict(zip(total_names, total_distances))\n",
    "    idx_min = np.argmin(total_distances)\n",
    "\n",
    "    distance, name = total_distances[idx_min], total_names[idx_min]\n",
    "    conn_db.close()\n",
    "\n",
    "    if distance < threshold:\n",
    "        return name, distance, total_result\n",
    "    else:\n",
    "        name = \"Unknown Person\"\n",
    "        return name, distance, total_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91d20d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model[normal quality] init ..\n",
      "model success !\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmin of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19656/3205969303.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompare_face\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"total_result:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19656/3884526428.py\u001b[0m in \u001b[0;36mcompare_face\u001b[1;34m(embeddings, threshold)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mtotal_distances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtotal_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_distances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0midx_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_distances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mdistance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_distances\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx_min\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx_min\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmin\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jerryold\\anaconda3\\envs\\test\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmin\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1273\u001b[0m     \"\"\"\n\u001b[1;32m-> 1274\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jerryold\\anaconda3\\envs\\test\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jerryold\\anaconda3\\envs\\test\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmin of an empty sequence"
     ]
    }
   ],
   "source": [
    "img_path = 'testdata/Suzy.jpg'\n",
    "detector = RetinaFace(quality=\"normal\")\n",
    "onnx_path = \"model/arcface_r100_v1.onnx\"\n",
    "extractor = rt.InferenceSession(onnx_path)\n",
    "file_path = 'database'\n",
    "db_path = 'database.db'\n",
    "threshold = 1\n",
    "sqlite3.register_adapter(np.ndarray, adapt_array)\n",
    "sqlite3.register_converter(\"ARRAY\", convert_array)\n",
    "\n",
    "if not os.path.exists(db_path):\n",
    "    create_db(db_path, file_path)\n",
    "\n",
    "img_rgb, detections = face_detect(img_path)\n",
    "position, landmarks, embeddings = get_embeddings(img_rgb, detections)\n",
    "\n",
    "for i, embedding in enumerate(embeddings):\n",
    "    name, distance, total_result = compare_face(embedding, threshold)\n",
    "    print(\"total_result:\", total_result)\n",
    "\n",
    "    cv2.rectangle(img_rgb, (position[i][0], position[i][1]), (position[i][2], position[i][3]), (255, 0, 0), 2)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(img_rgb, name + ', ' + str(distance), (position[i][0] + 10, position[i][1] - 10), font, 0.8, (255, 255, 0), 2)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img_rgb / 255)\n",
    "_ = plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
